import asyncio
import os
from pydantic import BaseModel, Field
# from google.colab import userdata
import json
import re
import sqlite3

# Imports das bibliotecas necess√°rias
from crawl4ai import (
    AsyncWebCrawler,
    CrawlerRunConfig
)
import litellm
from dotenv import load_dotenv

load_dotenv()

API_KEY = os.getenv("GROQ_API_KEY")


#URL A SER ESTUDADA, MODIFICAR AQUI
TARGET_URL = "https://www.dados.ms.gov.br/"


# ESTRUTURAS DE DADOS E TOKENS

# Schema para a coleta de evid√™ncias dos 13 crit√©rios principais pela IA
class EvidenceCollection(BaseModel):
    provide_api_reference: bool = Field(default=False, description="Verdadeiro se a p√°gina menciona uma API.")
    provide_api_reference_reasoning: str = Field(default="", description="Cita√ß√£o direta do texto que comprova a exist√™ncia de uma API.")
    provide_metadata: bool = Field(default=False, description="Verdadeiro se a p√°gina cont√©m metadados estruturados.")
    provide_metadata_reasoning: str = Field(default="", description="Cita√ß√£o direta do texto que descreve os metadados.")
    provide_descriptive_metadata: bool = Field(default=False, description="Verdadeiro se a p√°gina possui t√≠tulo e descri√ß√£o claros.")
    provide_descriptive_metadata_reasoning: str = Field(default="", description="Cita√ß√£o direta do t√≠tulo ou descri√ß√£o.")
    provide_data_license_information: bool = Field(default=False, description="Verdadeiro se a p√°gina menciona a licen√ßa de uso dos dados.")
    provide_data_license_information_reasoning: str = Field(default="", description="Cita√ß√£o direta da men√ß√£o √† licen√ßa.")
    provide_data_provenance_information: bool = Field(default=False, description="Verdadeiro se a p√°gina informa a origem dos dados.")
    provide_data_provenance_information_reasoning: str = Field(default="", description="Cita√ß√£o direta da informa√ß√£o de origem.")
    provide_a_version_indicator: bool = Field(default=False, description="Verdadeiro se h√° um indicador de vers√£o ou data de atualiza√ß√£o.")
    provide_a_version_indicator_reasoning: str = Field(default="", description="Cita√ß√£o direta da data ou vers√£o.")
    gather_feedback_from_data_consumers: bool = Field(default=False, description="Verdadeiro se existe um mecanismo de feedback.")
    gather_feedback_from_data_consumers_reasoning: str = Field(default="", description="Cita√ß√£o direta do mecanismo de feedback.")
    provide_bulk_download: bool = Field(default=False, description="Verdadeiro se h√° op√ß√£o de download em lote.")
    provide_bulk_download_reasoning: str = Field(default="", description="Cita√ß√£o direta da op√ß√£o de download em lote.")
    provide_data_up_to_date: bool = Field(default=False, description="Verdadeiro se os dados parecem ser recentes e atualizados?")
    provide_data_up_to_date_reasoning: str = Field(default="", description="Cita√ß√£o direta que indique a recente atualiza√ß√£o dos dados.")
    use_persistent_URIs_as_identifiers_of_datasets: bool = Field(default=False, description="Verdadeiro se as URLs parecem ser est√°veis e persistentes.")
    use_persistent_URIs_as_identifiers_of_datasets_reasoning: str = Field(default="", description="Justificativa da an√°lise sobre a persist√™ncia das URIs.")
    use_machine_readable_standardized_data_formats: bool = Field(default=False, description="Verdadeiro se os dados s√£o oferecidos em formatos como CSV, JSON, XML.")
    use_machine_readable_standardized_data_formats_reasoning: str = Field(default="", description="Cita√ß√£o direta dos formatos dispon√≠veis.")
    provide_data_in_multiple_formats: bool = Field(default=False, description="Verdadeiro se os dados est√£o dispon√≠veis em mais de um formato.")
    provide_data_in_multiple_formats_reasoning: str = Field(default="", description="Cita√ß√£o direta que comprove a exist√™ncia de m√∫ltiplos formatos.")
    cite_the_original_publication: bool = Field(default=False, description="Verdadeiro se os dados citam a publica√ß√£o original ou a fonte.")
    cite_the_original_publication_reasoning: str = Field(default="", description="Cita√ß√£o direta da refer√™ncia √† publica√ß√£o original.")

# Schema para o julgamento final do 14¬∫ crit√©rio pela IA "s√™nior"
class FalsePositiveJudgement(BaseModel):
    possible_false_positive: bool = Field(description="Julgamento final: Verdadeiro se a p√°gina √© um 'falso positivo'.")
    possible_false_positive_reasoning: str = Field(description="A justificativa concisa para o julgamento de falso positivo, baseada no resumo da an√°lise.")

# Mapa de tokens completo, derivado sua documenta√ß√£o
TOKEN_MAP = {
    "provide_api_reference": ["api", "apis", "documentacao api", "webservice", "rest", "restful", "get", "headers", "post", "delete", "put", "swagger", "apigility", "restify", "restlet"],
    "provide_metadata": ["metadados", "informacoes adicionais", "dicionario", "dicionarios", "dicionario dados", "taxonomia", "criterio", "criterios", "descricao conjunto dados", "titulo", "uri", "palavra chave", "palavras chave", "data publicacao", "data criacao", "criacao", "frequencia", "atualizacao", "data atualizacao", "contato", "granularidade", "referencia", "referencias", "responsavel", "responsaveis", "idioma", "fonte", "fontes", "versao", "mantenedor", "mantenedores", "tema", "formato data", "metadado estrutural", "metadados estruturais", "campo", "campos", "tipo dados", "metrica", "ultima modificacao", "ultima atualizacao", "descricao", "cobertura geografica", "cobertura temporal", "escopo geopolitico", "autor", "autores", "criado", "entidade responsavel", "ponto contato", "periodo temporal", "data ultima modificacao", "temas", "categorias", "formato", "formato midia", "licenca", "identificador", "relacao", "tipo conteudo", "recursos"],
    "provide_descriptive_metadata": ["title", "og:description", "publica√ß√£o", "modifica√ß√£o", "e-mail", "email"],
    "provide_data_license_information": ["licen√ßa", "tipo licen√ßa", "termos licen√ßa", "restri√ß√µes", "restri√ß√£o", "licen√ßas", "creative commons", "cc by", "cc by-sa", "cc by sa", "cco", "ec 0", "open database license", "odbl", "general public license", "gnu gpl", "gpl", "crel", "odrl", "odrs"],
    "provide_data_provenance_information": ["fonte", "fontes", "criador", "criadores", "responsavel", "responsaveis", "area responsavel", "mantenedor", "mantenedores", "autor", "autores", "editor", "editores", "editoras", "publicado", "publicador", "proveniencia"],
    "provide_a_version_indicator": ["modifica√ß√£o", "modificado", "atualiza√ß√£o", "atualizado", "atualizados", "revis√£o"],
    "gather_feedback_from_data_consumers": ["contato", "feedback", "formulario", "rank", "ranqueamento", "esperado", "avaliacao", "avaliacoes", "ajuda", "duvidas", "duvida", "comunique", "qualidade dados", "qualidade", "comentario", "questionamento", "classifica", "classificacao", "correcao", "revisao", "compartilhar", "compartilhe", "informe", "fale", "entre", "sugestoes", "telefone"],
    "provide_bulk_download": [".zip", ".rar", ".7z", ".tar", ".gz", "data", "atualizacao", "ultima", "frequencia", "criado", "criacao", "atualizado", "cobertura", "temporal", "validade"],
    "provide_data_up_to_date": ["modifica√ß√£o", "modificado", "atualiza√ß√£o", "atualizado", "atualizados", "revis√£o"],
    "use_persistent_URIs_as_identifiers_of_datasets": ["uri", "persistente", "identificador √∫nico", "link permanente", "permalink", "doi", "https://", "http://"],
    "use_machine_readable_standardized_data_formats": ["dataset", "dump:", "datastore", "dados abertos", "dados", "conjunto de dados", "conjunto dados", ".csv", ".json", ".xml", ".rdf", ".xlsx", ".pdf", ".ods", ".zip", ".dat", ".id", ".ind", ".map", ".tab", ".jsonld", ".ttl", ".tsv", ".xls"],
    "provide_data_in_multiple_formats": [".csv", ".json", ".xml", ".rdf", ".xlsx", "ods", ".zip", ".dat", ".id", ".ind", ".map", ".tab", "formatos"],
    "cite_the_original_publication": ["fonte", "procedencia", "citacao", "publicador", "disponivel", "referencia", "referencias"]
}

# FUN√á√ïES AUXILIARES

def chunk_text(text, chunk_size_chars):
    """Divide um texto grande em peda√ßos de um tamanho m√°ximo de caracteres."""
    return [text[i:i + chunk_size_chars] for i in range(0, len(text), chunk_size_chars)]

# FUN√á√ÉO PRINCIPAL

async def main():

    # URL ALVO:

    url_alvo = TARGET_URL
    print(f"üöÄ Iniciando pipeline ROBUSTO com processamento em lotes para: {url_alvo}")

    try:
        # --- ETAPA 1: COLETA DE EVID√äNCIAS ---
        print("\n--- Etapa 1: Coletando e analisando evid√™ncias para os 13 crit√©rios... ---")

        async with AsyncWebCrawler() as crawler:
            result_crawl = await crawler.arun(url=url_alvo, config=CrawlerRunConfig())
        full_cleaned_text = result_crawl.markdown.lower()
        evidence_dossier = ""
        sentences = re.split(r'(?<!\w\w.)(?<![A-Z][a-z].)(?<=\.|\?)\s', full_cleaned_text)
        found_tokens_map = {topic: set() for topic in TOKEN_MAP.keys()}

        for topic, keywords in TOKEN_MAP.items():
            for sentence in sentences:
                matching_keywords = [keyword for keyword in keywords if keyword in sentence]
                if matching_keywords:
                    evidence_dossier += f"- {sentence.strip()}\n"
                    for kw in matching_keywords:
                        found_tokens_map[topic].add(kw)

        TOKEN_LIMIT_CHARS = 8000
        text_chunks = chunk_text(evidence_dossier, TOKEN_LIMIT_CHARS)

        partial_results = []
        print(f"  > Dossi√™ dividido em {len(text_chunks)} pacote(s) para an√°lise...")
        for i, chunk in enumerate(text_chunks):
            print(f"  > Analisando evid√™ncias no pacote {i + 1} de {len(text_chunks)}...")
            try:
                # ### REFINAMENTO FINAL DO PROMPT ###
                user_prompt_evidence = f"""
                Analise o dossi√™ de evid√™ncias abaixo para preencher os campos da ferramenta 'EvidenceCollection'.

                **Regras Estritas:**
                1. Para cada crit√©rio, avalie se as evid√™ncias no dossi√™ o comprovam.
                2. Se comprovado, defina o campo booleano como `True` e o campo `_reasoning` com a CITA√á√ÉO DIRETA da evid√™ncia.
                3. Se n√£o houver evid√™ncia, defina o campo booleano como `False` e o campo `_reasoning` como uma string vazia.
                4. Sua resposta deve ser **exclusivamente** uma chamada √† ferramenta `EvidenceCollection` no formato JSON. N√£o inclua texto introdut√≥rio, explica√ß√µes ou resumos. Apenas o JSON.

                ### DOSSI√ä DE EVID√äNCIAS ###
                {chunk}
                """

                response = await litellm.acompletion(
                    model="groq/llama3-70b-8192",
                    messages=[{"role": "user", "content": user_prompt_evidence}],
                    tools=[{"type": "function", "function": {"name": "EvidenceCollection", "description": "Formul√°rio para coletar evid√™ncias de 13 princ√≠pios de dados abertos.", "parameters": EvidenceCollection.model_json_schema()}}],
                    tool_choice={"type": "function", "function": {"name": "EvidenceCollection"}},

                    api_key=API_KEY

                )
                arguments = json.loads(response.choices[0].message.tool_calls[0].function.arguments)
                partial_results.append(EvidenceCollection.model_validate(arguments))
                print(f"  > Pacote {i + 1} analisado com sucesso.")
            except Exception as e:
                print(f"  > ERRO ao processar o pacote {i + 1}: {e}")
                # Adicionamos uma pausa antes de continuar, pode ajudar em erros de API moment√¢neos
                await asyncio.sleep(20)
                continue

        # Verifica se algum pacote foi processado com sucesso
        if not partial_results:
            print("\n‚ùå Nenhum pacote de evid√™ncias p√¥de ser processado. An√°lise abortada.")
            return

        # Jun√ß√£o dos resultados dos 13 crit√©rios
        evidence_analysis = EvidenceCollection()
        unique_reasonings = {field: set() for field in EvidenceCollection.model_fields if field.endswith("_reasoning")}
        for partial in partial_results:
            for field, value in partial.model_dump().items():
                if field.endswith("_reasoning") and value:
                    unique_reasonings[field].add(value.strip())
                elif isinstance(value, bool) and value:
                    setattr(evidence_analysis, field.replace("_reasoning", ""), True)
        for field, reason_set in unique_reasonings.items():
            if reason_set:
                setattr(evidence_analysis, field, " | ".join(sorted(list(reason_set))))

        print("‚úÖ Coleta de evid√™ncias conclu√≠da.")

        # ETAPA 2: JULGAMENTO FINAL 
        print("\n--- Etapa 2: Solicitando julgamento final do 'Auditor S√™nior'... ---")

        detailed_report_for_judgement = "RELAT√ìRIO DE AN√ÅLISE DETALHADA PARA JULGAMENTO:\n\n"
        for field in EvidenceCollection.model_fields:
            if not field.endswith("_reasoning"):
                status = "SIM" if getattr(evidence_analysis, field) else "N√ÉO"
                evidence = getattr(evidence_analysis, f"{field}_reasoning") or "Nenhuma evid√™ncia encontrada."
                detailed_report_for_judgement += f"- {field}: {status}\n  Evid√™ncia(s) da IA: {evidence}\n"
        rule_keys = ["provide_metadata", "provide_descriptive_metadata", "cite_the_original_publication", "use_machine_readable_standardized_data_formats"]
        num_indicators = sum(1 for key in rule_keys if getattr(evidence_analysis, key))
        detailed_report_for_judgement += f"\nRegra de Refer√™ncia do Documento: um portal √© considerado fraco ('falso positivo') se menos de 3 de 4 indicadores chave forem positivos. Resultado desta an√°lise: {num_indicators} de 4 indicadores foram positivos."
        await asyncio.sleep(20)
        final_judgement_response = await litellm.acompletion(
            model="groq/llama3-70b-8192",
            messages=[
                {"role": "system", "content": "Voc√™ √© um auditor de dados s√™nior. Sua tarefa √© fazer um julgamento final sobre a qualidade de um portal de dados com base em um relat√≥rio detalhado que inclui as evid√™ncias encontradas."},
                {"role": "user", "content": f"Com base no relat√≥rio detalhado a seguir, fa√ßa um julgamento final e justificado: esta p√°gina deve ser considerada um 'falso positivo' (um portal que parece bom na superf√≠cie, mas cujas evid√™ncias s√£o fracas, gen√©ricas ou contradit√≥rias)?\n\n### RELAT√ìRIO DETALHADO ###\n{detailed_report_for_judgement}"}
            ],
            tools=[{"type": "function", "function": {"name": "FalsePositiveJudgement", "description": "Formul√°rio para o julgamento final de falso positivo.", "parameters": FalsePositiveJudgement.model_json_schema()}}],
            tool_choice={"type": "function", "function": {"name": "FalsePositiveJudgement"}},
            
            api_key= API_KEY
        )
        judgement_arguments = json.loads(final_judgement_response.choices[0].message.tool_calls[0].function.arguments)
        final_judgement = FalsePositiveJudgement.model_validate(judgement_arguments)
        print("‚úÖ Julgamento final recebido.")

        # ETAPA 3: APRESENTA√á√ÉO DOS RESULTADOS 
        print("\n\n--- RESULTADO FINAL DA AUDITORIA ---")
        for field in EvidenceCollection.model_fields:
            if not field.endswith("_reasoning"):
                value = getattr(evidence_analysis, field)
                reasoning = getattr(evidence_analysis, f"{field}_reasoning")
                status = "‚úÖ SIM" if value else "‚ùå N√ÉO"
                tokens_encontrados = sorted(list(found_tokens_map.get(field, [])))
                print(f"\n- {field.replace('_', ' ').capitalize()}: {status}")
                if tokens_encontrados:
                    print(f"  Tokens Encontrados (Filtro): {tokens_encontrados}")
                print(f"  Evid√™ncia (IA): {reasoning if reasoning else 'Nenhuma evid√™ncia direta encontrada.'}")
        print("\n--- VEREDITO FINAL (AUDITOR S√äNIOR) ---")
        status = "üö® SIM, RISCO DE FALSO POSITIVO" if final_judgement.possible_false_positive else "‚úÖ N√ÉO, PORTAL CONSISTENTE"
        print(f"\n- Possible false positive: {status}")
        print(f"  Justificativa do Auditor: {final_judgement.possible_false_positive_reasoning}")
        insert_results_into_db(url_alvo, evidence_analysis, final_judgement, found_tokens_map)

    except Exception as e:
        print(f"üö® Erro inesperado durante a execu√ß√£o: {e}")

    
def insert_results_into_db(url, evidence_analysis: EvidenceCollection, final_judgement: FalsePositiveJudgement, found_tokens_map: dict):
    conn = None
    cursor = None
    try:
        conn = sqlite3.connect('opendata.db') 
        cursor = conn.cursor()

        # Cria tabelas se n√£o existirem
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS tokens (
            site_id INTEGER PRIMARY KEY AUTOINCREMENT,
            url TEXT NOT NULL,
            provide_api_reference BOOLEAN,
            provide_metadata BOOLEAN,
            provide_descriptive_metadata BOOLEAN,
            provide_data_license_information BOOLEAN,
            provide_data_provenance_information BOOLEAN,
            provide_a_version_indicator BOOLEAN,
            gather_feedback_from_data_consumers BOOLEAN,
            provide_bulk_download BOOLEAN,
            provide_data_up_to_date BOOLEAN,
            use_persistent_uris_as_identifiers_of_datasets BOOLEAN,
            use_machine_readable_standardized_data_formats BOOLEAN,
            provide_data_in_multiple_formats BOOLEAN,
            cite_the_original_publication BOOLEAN,
            possible_false_positive BOOLEAN,
            possible_false_positive_reasoning TEXT
        );
        """)

        # Inserir na tabela tokens
        insert_tokens = """
        INSERT INTO tokens (
            url,
            provide_api_reference,
            provide_metadata,
            provide_descriptive_metadata,
            provide_data_license_information,
            provide_data_provenance_information,
            provide_a_version_indicator,
            gather_feedback_from_data_consumers,
            provide_bulk_download,
            provide_data_up_to_date,
            use_persistent_uris_as_identifiers_of_datasets,
            use_machine_readable_standardized_data_formats,
            provide_data_in_multiple_formats,
            cite_the_original_publication,
            possible_false_positive,
            possible_false_positive_reasoning
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """
        values_tokens = (
            url,
            evidence_analysis.provide_api_reference,
            evidence_analysis.provide_metadata,
            evidence_analysis.provide_descriptive_metadata,
            evidence_analysis.provide_data_license_information,
            evidence_analysis.provide_data_provenance_information,
            evidence_analysis.provide_a_version_indicator,
            evidence_analysis.gather_feedback_from_data_consumers,
            evidence_analysis.provide_bulk_download,
            evidence_analysis.provide_data_up_to_date,
            evidence_analysis.use_persistent_URIs_as_identifiers_of_datasets,
            evidence_analysis.use_machine_readable_standardized_data_formats,
            evidence_analysis.provide_data_in_multiple_formats,
            evidence_analysis.cite_the_original_publication,
            final_judgement.possible_false_positive,
            final_judgement.possible_false_positive_reasoning
        )
        cursor.execute(insert_tokens, values_tokens)
        site_id = cursor.lastrowid

        conn.commit()
        print(f"‚úÖ Resultados armazenados no banco local com site_id = {site_id}")

    except Exception as e:
        print(f"üö® ERRO ao inserir no banco de dados local: {e}")
    finally:
        if cursor:
            cursor.close()
        if conn:
            conn.close()
        print("üîí Conex√£o com o banco de dados fechada.")

# Executa a fun√ß√£o principal
if __name__ == "__main__":
    asyncio.run(main())